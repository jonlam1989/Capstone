{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv              # environment variables\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# assign environment variables\n",
    "PASSWORD = os.getenv('MariaDB_Password')\n",
    "USER = os.getenv('MariaDB_Username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Credit Card App\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract json file\n",
    "def extract_json(file):\n",
    "    return spark.read.json(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation Functions \n",
    "- Customer \n",
    "- Branch \n",
    "- Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform customer data\n",
    "def transform_customer(dataframe):\n",
    "    # name transformation\n",
    "    dataframe = dataframe.withColumn('FIRST_NAME', initcap(dataframe['FIRST_NAME']))                         # convert to title case\n",
    "    dataframe = dataframe.withColumn('MIDDLE_NAME', lower(dataframe['MIDDLE_NAME']))                         # convert to lower case\n",
    "    dataframe = dataframe.withColumn('LAST_NAME', initcap(dataframe['LAST_NAME']))                           # convert to title case\n",
    "\n",
    "    # address transformation\n",
    "    dataframe = dataframe.withColumn('FULL_STREET_ADDRESS', \n",
    "                                     concat_ws(', ', dataframe['STREET_NAME'], dataframe['APT_NO']))         # concat street name + apt no\n",
    "    dataframe = dataframe.drop('APT_NO', 'STREET_NAME')                                                      # drop columns\n",
    "\n",
    "    # phone number transformation\n",
    "    dataframe = dataframe.withColumn('CUST_PHONE', concat(lit('(781)'),                                      # change format of phone number\n",
    "                                                          substring(dataframe['CUST_PHONE'], 1, 3), \n",
    "                                                          lit('-'), \n",
    "                                                          substring(dataframe['CUST_PHONE'], 3, 4)))\n",
    "    \n",
    "    # convert data types\n",
    "    dataframe = dataframe.withColumn('SSN', dataframe['SSN'].cast('int'))\n",
    "    dataframe = dataframe.withColumn('CUST_ZIP', dataframe['CUST_ZIP'].cast('int'))\n",
    "    dataframe = dataframe.withColumn('LAST_UPDATED', to_timestamp(dataframe['LAST_UPDATED']))\n",
    "\n",
    "    # rearrange columns\n",
    "    rearranged_customer_df = dataframe.select('SSN', \n",
    "                                                'FIRST_NAME', \n",
    "                                                'MIDDLE_NAME', \n",
    "                                                'LAST_NAME',\n",
    "                                                'CREDIT_CARD_NO',\n",
    "                                                'FULL_STREET_ADDRESS',\n",
    "                                                'CUST_CITY',\n",
    "                                                'CUST_STATE',\n",
    "                                                'CUST_COUNTRY',\n",
    "                                                'CUST_ZIP',\n",
    "                                                'CUST_PHONE',\n",
    "                                                'CUST_EMAIL',\n",
    "                                                'LAST_UPDATED')\n",
    "    return rearranged_customer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform branch data \n",
    "def transform_branch(dataframe):\n",
    "    # zip code transformation\n",
    "    dataframe = dataframe.fillna(999999, subset=['BRANCH_ZIP'])                                              # replace null values\n",
    "\n",
    "    # phone number transformation\n",
    "    dataframe = dataframe.withColumn('BRANCH_PHONE', concat(lit('(781)'),                                    # change format of phone number\n",
    "                                                            substring(dataframe['BRANCH_PHONE'], 1, 3), \n",
    "                                                            lit('-'), \n",
    "                                                            substring(dataframe['BRANCH_PHONE'], 3, 4)))\n",
    "    \n",
    "    # convert data type\n",
    "    dataframe = dataframe.withColumn('BRANCH_CODE', dataframe['BRANCH_CODE'].cast('int'))\n",
    "    dataframe = dataframe.withColumn('BRANCH_ZIP', dataframe['BRANCH_ZIP'].cast('int'))\n",
    "    dataframe = dataframe.withColumn('LAST_UPDATED', to_timestamp(dataframe['LAST_UPDATED']))\n",
    "\n",
    "    # rearrange columns\n",
    "    rearranged_branch_df = dataframe.select('BRANCH_CODE',\n",
    "                                'BRANCH_NAME',\n",
    "                                'BRANCH_STREET',\n",
    "                                'BRANCH_CITY',\n",
    "                                'BRANCH_STATE',\n",
    "                                'BRANCH_ZIP',\n",
    "                                'BRANCH_PHONE',\n",
    "                                'LAST_UPDATED')\n",
    "    \n",
    "    return rearranged_branch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform credit data \n",
    "def transform_credit(dataframe):\n",
    "    # date transformation\n",
    "    dataframe = dataframe.withColumn('TIMEID',                                                               # change format of date\n",
    "                                     concat_ws('-', dataframe['YEAR'], dataframe['MONTH'], dataframe['DAY']).cast('date'))\n",
    "    \n",
    "    # remove all hypens\n",
    "    dataframe = dataframe.withColumn('TIMEID', regexp_replace(dataframe['TIMEID'], '-', ''))\n",
    "    dataframe = dataframe.drop('YEAR', 'MONTH', 'DAY')\n",
    "\n",
    "    # convert data type\n",
    "    dataframe = dataframe.withColumn('BRANCH_CODE', dataframe['BRANCH_CODE'].cast('int'))\n",
    "    dataframe = dataframe.withColumn('CUST_SSN', dataframe['CUST_SSN'].cast('int'))\n",
    "    dataframe = dataframe.withColumn('TRANSACTION_ID', dataframe['TRANSACTION_ID'].cast('int'))\n",
    "\n",
    "    # rename column\n",
    "    dataframe = dataframe.withColumnRenamed('CREDIT_CARD_NO', 'CUST_CC_NO')\n",
    "    \n",
    "    # rearrange columns\n",
    "    rearranged_credit_df = dataframe.select('CUST_CC_NO',\n",
    "                                            'TIMEID',\n",
    "                                            'CUST_SSN',\n",
    "                                            'BRANCH_CODE',\n",
    "                                            'TRANSACTION_TYPE',\n",
    "                                            'TRANSACTION_VALUE',\n",
    "                                            'TRANSACTION_ID')\n",
    "    \n",
    "    return rearranged_credit_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load/write data to MariaDB\n",
    "def load_to_db(dataframe, db_name, table_name, user, password):\n",
    "    dataframe.write.format(\"jdbc\") \\\n",
    "                    .mode(\"append\") \\\n",
    "                    .option(\"url\", f\"jdbc:mysql://localhost:3306/{db_name}\") \\\n",
    "                    .option(\"dbtable\", table_name) \\\n",
    "                    .option(\"user\", user) \\\n",
    "                    .option(\"password\", password) \\\n",
    "                    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load/write data to csv file to use for interactive dashboard\n",
    "def load_to_csv(dataframe, file):\n",
    "    pandas_df = dataframe.toPandas()\n",
    "    pandas_df.to_csv(file, mode='a', index=False)               # don't include the index in the csv file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "def log(message):\n",
    "    now = datetime.now()                                        # get current timestamp\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'                      # Year-Month_name-Day-Hour-Minute-Second\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "\n",
    "    with open('cc_logfile.txt', 'a') as f:                      # outputs logs to cc_logfile.txt\n",
    "        f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETL Pipelines\n",
    "- Customer\n",
    "- Branch\n",
    "- Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer ETL Pipeline\n",
    "log('Customer ETL Job Started')\n",
    "#-----------------------------------------------------------\n",
    "log('Customer Extraction Started')\n",
    "customer_df = extract_json('cdw_files/cdw_sapp_custmer.json')\n",
    "log('Customer Extraction Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Customer Transformation Started')\n",
    "transformed_customer_df = transform_customer(customer_df)\n",
    "log('Customer Transformation Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Customer Loading Started')\n",
    "load_to_db(transformed_customer_df,     # dataframe\n",
    "           'creditcard_capstone',       # db_name\n",
    "           'CDW_SAPP_CUSTOMER',         # table_name\n",
    "           USER,                        # user_name\n",
    "           PASSWORD)                    # password\n",
    "load_to_csv(transformed_customer_df, 'cleaned_files/cleaned_customer.csv')                                   # for interactive dashboard\n",
    "log('Customer Loading Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Customer ETL Job Ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Branch ETL Pipeline\n",
    "log('Branch ETL Job Started')\n",
    "#-----------------------------------------------------------\n",
    "log('Branch Extraction Started')\n",
    "branch_df = extract_json('cdw_files/cdw_sapp_branch.json')\n",
    "log('Branch Extraction Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Branch Transformation Started')\n",
    "transformed_branch_df = transform_branch(branch_df)\n",
    "log('Branch Transformation Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Branch Loading Started')\n",
    "load_to_db(transformed_branch_df,       # dataframe\n",
    "           'creditcard_capstone',       # db_name\n",
    "           'CDW_SAPP_BRANCH',           # table_name\n",
    "           USER,                        # user_name\n",
    "           PASSWORD)                    # password\n",
    "load_to_csv(transformed_branch_df, 'cleaned_files/cleaned_branch.csv')                                       # for interactive dashboard\n",
    "log('Branch Loading Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Branch ETL Job Ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit ETL Pipeline\n",
    "log('Credit ETL Job Started')\n",
    "#-----------------------------------------------------------\n",
    "log('Credit Extraction Started')\n",
    "credit_df = extract_json('cdw_files/cdw_sapp_credit.json')\n",
    "log('Credit Extraction Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Credit Transformation Started')\n",
    "transformed_credit_df = transform_credit(credit_df)\n",
    "log('Credit Transformation Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Credit Loading Started')\n",
    "load_to_db(transformed_credit_df,       # dataframe\n",
    "           'creditcard_capstone',       # db_name\n",
    "           'CDW_SAPP_CREDIT_CARD',      # table_name\n",
    "           USER,                        # user_name\n",
    "           PASSWORD)                    # password\n",
    "load_to_csv(transformed_credit_df, 'cleaned_files/cleaned_credit.csv')                                       # for interactive dashboard\n",
    "log('Credit Loading Ended')\n",
    "#-----------------------------------------------------------\n",
    "log('Credit ETL Job Ended')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17ca842869ffbfc3c9d460e03d0ec6a8e2778b1d7a95dcef3c99fb910aa8206c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
